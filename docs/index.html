<!DOCTYPE html>
<html>
	<head>
		<title>Temporal Set Inversion</title>
		<meta charset="utf-8">
		<link rel="stylesheet" href="index.css">
		<link href="https://fonts.cdnfonts.com/css/linux-libertine-o" rel="stylesheet">
		<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
		<script type="text/javascript"
  			src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
		</script>
		<script type="text/x-mathjax-config">
			MathJax.Hub.Config({
			  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
			});
		</script>
	</head>
	<body>
		<div class="content">
			<h1>Temporal Set Inversion for Animated Implicits</h1>
			<h3>ACM Transactions on Graphics (SIGGRAPH 2023)</h3>
			<h3><a href="https://www.linkedin.com/in/kavosh-jazar/">Kavosh Jazar</a>, <a href="https://www.cs.mcgill.ca/~kry/">Paul G. Kry</a></h3>
			<h3>McGill University</h3>
			<p>
				<a class="icon" href="https://github.com/cryvosh/TemporalSetInversion">
					<i class="fa fa-github" style="font-size:30px;"></i> Source code (github)
				</a>
				<br>
				<a class="icon" href="Temporal_Set_Inversion.pdf">
					<i class="fa fa-file-pdf-o" style="font-size:30px;"></i> Paper pdf (37 mb)
				</a>
			</p>
			<!-- <i class="fa fa-link" style="font-size:27px;"></i> -->
			<div style="width:100%;display:table;;">
				<img src="1.jpg">
				<img src="2.jpg">
				<img src="3.jpg">
				<img src="4.jpg">
			</div>
			<p align="justify">
				Fig 1. Snapshots of an animated implicit surface at timesteps $68, 150, 265$ and $330$ showing in red the regions that were evaluated in each timestep to sparsely update a $1024^3$ voxelization of the scene only as and where is necessary to maintain bounded error in the surface. For comparison, existing approaches would color the entire surface red in each timestep, thus wasting resources in static or slowly-evolving areas far from the motion. The runtime of our method depends on the moving surface area per frame and achieves here a $\sim3\times$ speedup compared to full per-frame re-evaluation at a temporal error tolerance of $\delta=0.01$.
			</p>
			<h2>Abstract</h2>
			<p align="justify">
				We exploit the temporal coherence of closed-form animated implicit surfaces by locally re-evaluating an octree-like discretization of the implicit field only as and where is necessary to rigorously maintain a global error invariant over time, thereby saving resources in static or slowly-evolving areas far from the motion where per-frame updates are not necessary. We treat implicit surface rendering as a special case of the continuous constraint satisfaction problem of set inversion, which seeks preimages of arbitrary sets under vector-valued functions. From this perspective, we formalize a temporally-coherent set inversion algorithm that localizes changes in the field by range-bounding its time derivatives using interval arithmetic. We implement our algorithm on the GPU using persistent thread scheduling and apply it to the scalar case of implicit surface and swept volume rendering where we achieve significant speedups in complex scenes with localized deformations like those found in games and modelling applications where interactivity is required and bounded-error approximation is acceptable.
			</p>
			<h2>Citation</h2>
<pre>
@article {jazar2023,
	author     = {Jazar, Kavosh and Kry, Paul},
	title      = {Temporal Set Inversion for Animated Implicits},
	publisher  = {Association for Computing Machinery},
	journal    = {ACM Trans. Graph.},
	address    = {New York, NY, USA},
	doi        = {10.1145/3592448},
	year       = {2023},
	volume     = {42},
	month      = {8},
	number     = {4},
}
</pre>
			<h2>Live Presentation</h2>
			<div id="pres_video">
				<iframe width="100%" height="100%" src="https://www.youtube.com/embed/svmSJ0wMxbs" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
			</div>
			<h2>Supplemental Video</h2>
			<div id="sup_video">
				<iframe width="100%" height="100%" src="https://www.youtube.com/embed/Jlor8zIZbPM" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
			</div>
			<h2>Acknowledgements</h2>
			<p align="justify">
				We'd like to thank Inigo Quilez, David P. Sanders, and Luc Jaulin for their inspiring work, as well as Joey Litalien, Michael Kenzel, Connor Fitzgerald, Kenny Erleben, and the anonymous reviewers for their help. We also acknowledge the support of the Natural Sciences and Engineering Research Council of Canada (NSERC).
				Our test scenes are based on the work of <a href=https://www.shadertoy.com/view/ldl3zN>Inigo Quilez</a>,  <a href=https://www.shadertoy.com/view/wlKXWc>yuntaRobo</a>, <a href=https://www.shadertoy.com/view/sdsXWr>The Art of Code</a>, and <a href=https://www.shadertoy.com/view/ldl3zN>Mariano Merchante</a>.
			</p>
		</div>
	</body>
	<footer></footer>
</html>